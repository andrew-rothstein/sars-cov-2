{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "import vcf\n",
    "\n",
    "from altair_saver import save\n",
    "from Bio import SeqIO\n",
    "from IPython.display import HTML\n",
    "from onecodex import Api\n",
    "from onecodex.notebooks.report import set_style, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocx = Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = os.environ.get(\"ONE_CODEX_REPORT_ENV\", \"draft\")\n",
    "\n",
    "if ENVIRONMENT == \"production\":\n",
    "    sample_uuid = os.environ[\"ONE_CODEX_SAMPLE_UUID\"]\n",
    "else:\n",
    "    sample_uuid = None\n",
    "    sample_filename = \"sample.fastq\"\n",
    "    \n",
    "sample = ocx.Samples.get(sample_uuid)    \n",
    "\n",
    "assert sample is not None, \"Sample does not exist\"\n",
    "sample_filename = sample.filename\n",
    "if not os.path.exists(sample_filename):\n",
    "    sample.download()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output paths\n",
    "VARIANTS_TSV_PATH = \"variants.tsv\"\n",
    "NEXTCLADE_JSON = \"nextclade.json\"\n",
    "NEXTCLADE_TSV_PATH = \"nextclade.tsv\"\n",
    "PANGOLIN_CSV_PATH = \"pangolin.csv\"\n",
    "BAM_PATH = \"covid19.bam\"\n",
    "\n",
    "# input paths\n",
    "REFERENCE_PATH = os.environ.get(\n",
    "    \"FASTA_REFERENCE\", \"/share/nCoV-2019.reference.fasta\"\n",
    ")\n",
    "\n",
    "# default illumina + ivar pipeline\n",
    "BED_FILE_PATH = os.environ.get(\"BED_FILE_PATH\", \"/share/ARTIC-V1.bed\")\n",
    "REFERENCE_NAME = os.path.basename(REFERENCE_PATH).rstrip('.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"SEQUENCING_PLATFORM\") == \"Oxford Nanopore\":\n",
    "#     print(\"Using ONT ARTIC v3 pipeline to call variants\")\n",
    "    MIN_DEPTH = 50\n",
    "    !/usr/local/bin/covid19_call_variants.artic.sh {sample_filename} > variants.log 2>&1\n",
    "else:\n",
    "#     print(\"Using short-read ARTIC v1 pipeline to call variants\")\n",
    "    MIN_DEPTH = 10\n",
    "    !/usr/local/bin/covid19_call_variants.sh {REFERENCE_PATH} {sample_filename} {BED_FILE_PATH} > variants.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process variants\n",
    "!post_process_variants.sh consensus.fa > variants.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference genome\n",
    "reference = list(SeqIO.parse(REFERENCE_PATH, \"fasta\"))\n",
    "reference_length = len(reference[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools depth $BAM_PATH > snps.depth 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reads = sample.primary_classification.results()[\"n_reads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools_view_output = !samtools view -F 2308 $BAM_PATH | wc -l\n",
    "n_mapped_reads = int(samtools_view_output[0])\n",
    "proportion_mapped_reads = n_mapped_reads / n_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_table = []\n",
    "\n",
    "with open(\"snps.depth\") as handle:\n",
    "    for line in handle:\n",
    "        row = line.strip().split(\"\\t\")\n",
    "        depth_table.append(\n",
    "            {\"reference\": row[0], \"position\": int(row[1]), \"depth\": int(row[2])}\n",
    "        )\n",
    "depth_table = pd.DataFrame(depth_table, columns=[\"reference\", \"position\", \"depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate genome coverage (what percent of bases are coveraged at X coverage)\n",
    "# Use a fixed reference length that we use for `samtools depth` above\n",
    "\n",
    "covered_sites = set()\n",
    "covered_sites_mindepth = set()\n",
    "\n",
    "for _, row in depth_table.iterrows():\n",
    "    row = row.to_dict()\n",
    "    if row[\"depth\"] >= 1:\n",
    "        covered_sites.add(row[\"position\"])\n",
    "    if row[\"depth\"] >= MIN_DEPTH:\n",
    "        covered_sites_mindepth.add(row[\"position\"])        \n",
    "\n",
    "cov = len(covered_sites) / reference_length\n",
    "cov_mindepth = len(covered_sites_mindepth) / reference_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean over windows because altair can't handle > 5k points ...\n",
    "binned_depths = []\n",
    "window_width = reference_length // 4500\n",
    "\n",
    "for i in range(1, reference_length, window_width):\n",
    "    window = depth_table.loc[\n",
    "        (depth_table[\"position\"] > i) & (depth_table[\"position\"] < i + window_width)\n",
    "    ]\n",
    "\n",
    "    binned_depths.append(\n",
    "        {\"position\": i, \"depth\": window[\"depth\"].mean(),}\n",
    "    )\n",
    "\n",
    "binned_depths = pd.DataFrame(binned_depths)\n",
    "mean_depth = depth_table[\"depth\"].mean() if not depth_table.empty else 0\n",
    "median_depth = depth_table[\"depth\"].median() if not depth_table.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Nextclade and Pangolin tables\n",
    "\n",
    "nextclade_table = pd.read_csv(NEXTCLADE_TSV_PATH, sep=\"\\t\")\n",
    "pangolin_table = pd.read_csv(PANGOLIN_CSV_PATH, sep=\",\")\n",
    "\n",
    "# Add to results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nextclade JSON\n",
    "with open(NEXTCLADE_JSON) as json_file:\n",
    "    nextclade_json = json.load(json_file)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate warnings if indels are detected? (ONT does not reliably detect these)\n",
    "warnings = []\n",
    "if nextclade_json['insertions'] != []:\n",
    "    warnings.append('Insertions are detected.')\n",
    "if nextclade_json['deletions'] != []:\n",
    "    warnings.append('Deletions are detected.')\n",
    "if warnings != []:\n",
    "    for warning in warnings:\n",
    "        display(warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variants table\n",
    "rows_list = []\n",
    "for subst in nextclade_json['substitutions']: # Each substitution is a dictionary\n",
    "    dict1 = {}\n",
    "    dict1['Position'] = subst['pos'] + 1 # JSON positions are 0-indexed; convert to 1-index\n",
    "    dict1['Ref'] = subst['refNuc']\n",
    "    dict1['Alt'] = subst['queryNuc']\n",
    "    if len(subst['aaSubstitutions']) != 0:\n",
    "        for mutation in subst['aaSubstitutions']:\n",
    "            dict1['Amino acid mutation'] = mutation['refAA'] + str(mutation['codon']) + mutation['queryAA']\n",
    "    else:\n",
    "        dict1['Amino acid mutation'] = ''\n",
    "    rows_list.append(dict1)\n",
    "\n",
    "variant_table = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in gene info\n",
    "df_orfs = pd.read_csv(\"/annot_table.orfs.txt\", \\\n",
    "    sep=\"\\t\", \\\n",
    "    header=None, \\\n",
    "    usecols=[0, 1, 2], \\\n",
    "    names=[\"gene\", \"start\", \"stop\"])\n",
    "\n",
    "for i in variant_table.index:\n",
    "    for j in df_orfs.index:\n",
    "        if df_orfs.loc[j, \"start\"] <= variant_table.loc[i, \"Position\"] <= df_orfs.loc[j, \"stop\"]:\n",
    "            variant_table.loc[i, \"Gene\"] = df_orfs.loc[j, \"gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in depth info\n",
    "!grep -v \"^#\" variants.vcf > variants.vcf.noheaders\n",
    "\n",
    "df_vcf = pd.read_csv(\"variants.vcf.noheaders\", \\\n",
    "                     sep='\\t', \\\n",
    "                     usecols=[1,7], \\\n",
    "                     names=['position','info'], \\\n",
    "                     index_col=['position']\\\n",
    "                    )\n",
    "for position in df_vcf.index:\n",
    "    SR = df_vcf.loc[position,'info'].rsplit(';SR=')[1].rsplit(';')[0]\n",
    "    ref_reads = int(SR.rsplit(',')[0]) + int(SR.rsplit(',')[1])\n",
    "    alt_reads = int(SR.rsplit(',')[2]) + int(SR.rsplit(',')[3])\n",
    "    variant_table.loc[position, 'Alt depth'] = int(alt_reads)\n",
    "    variant_table.loc[position, 'Alt frequency (%)'] = \"{:,.2f}\".format(alt_reads/(alt_reads + ref_reads)*100)\n",
    "    variant_table.loc[position, 'Total depth'] = int(ref_reads + alt_reads)\n",
    "\n",
    "variant_table = variant_table[['Position','Ref','Alt','Alt depth','Total depth','Alt frequency (%)','Gene','Amino acid mutation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snps = variant_table.shape[0]\n",
    "n_snps_mindepth = sum(variant_table['Total depth'] > MIN_DEPTH)\n",
    "\n",
    "nextclade_pm_count = nextclade_json['qc']['privateMutations']['total']\n",
    "nextclade_lineage = nextclade_json['clade']\n",
    "\n",
    "pangolin_lineage = pangolin_table['lineage'].iloc[0]\n",
    "pangolin_version = pangolin_table['pangoLEARN_version'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"SARS-CoV-2 (COVID-19) Sequencing Overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "This report summarizes the detection of SARS-CoV-2 in sample \n",
    "<strong>{sample_filename}</strong>. \n",
    "\n",
    "<p>This sample contained <strong>{n_reads:,}</strong> reads, with\n",
    "<strong>{proportion_mapped_reads:.1%}</strong> mapping to the \n",
    "<a href='https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3/' target='_blank'>Wuhan-Hu-1 reference</a>.\n",
    "Reads span <strong>{cov:.0%}</strong> of the genome, with a mean depth of <strong>{mean_depth:.0f}x</strong>, and {cov_mindepth:.0%} of the genome covered at depths >{MIN_DEPTH:}x.</p>\n",
    "\n",
    "<p>A total of <strong>{n_snps_mindepth}</strong> variant{'s were' if n_snps_mindepth != 1 else 'was'} detected at depths over {MIN_DEPTH:}x.\n",
    "This genome is classified as Pangolin lineage <strong>{pangolin_lineage}</strong> using PangoLEARN version {pangolin_version} and Nextclade lineage <strong>{nextclade_lineage}</strong> with {nextclade_pm_count} private mutation{'s' if nextclade_pm_count != 1 else ''}.</p>\"\"\"\n",
    "\n",
    "HTML(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage plot\n",
    "plot = (\n",
    "    alt.Chart(binned_depths)\n",
    "    .mark_area()\n",
    "    .transform_window(rolling_mean=\"mean(depth)\", frame=[-50, 50])\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"position\",\n",
    "            title=\"Genomic Coordinate\",\n",
    "            scale=alt.Scale(domain=[0, reference_length]),\n",
    "        ),\n",
    "        y=alt.Y(\"rolling_mean:Q\", scale=alt.Scale(type=\"linear\"), title=\"Depth\"),\n",
    "    )\n",
    "    .properties(\n",
    "        title=f\"SARS-CoV-2 ({REFERENCE_NAME})\",\n",
    "        width=550,\n",
    "        height=150,\n",
    "    )\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./nextclade.json\") as handle:\n",
    "    nextclade_results = json.load(handle)\n",
    "    assert len(nextclade_results) == 1, \"expected exactly 1 item in nextclade.json\"\n",
    "    nextclade = nextclade_results[0]\n",
    "    \n",
    "# # flatten nextclade results\n",
    "# # deletions don't have positions\n",
    "# nc_flat = []\n",
    "# for _type in {'substitutions', 'deletions', 'insertions'}:\n",
    "#     for row in nextclade[_type]:\n",
    "#         aa_key = f'aa{_type.capitalize()}'\n",
    "#         if len(row.get(aa_key, [])) == 0:\n",
    "#             # synonymous mutation\n",
    "#             nc_flat.append({\n",
    "#                 \"n\": 1,\n",
    "#                 \"type\": _type,\n",
    "#                 'ref': row.get('refNuc', '-'),\n",
    "#                 'pos': row.get('pos', row.get('start')),\n",
    "#                 'alt': row.get('queryNuc', '-'),\n",
    "#                 'gene': row.get('gene', '-'),\n",
    "#                 'ref_aa': '-',\n",
    "#                 'query_aa': '-'\n",
    "#             })\n",
    "#         else:\n",
    "#             for n, aa_substitution in enumerate(row[aa_key], start=1):\n",
    "#                 nc_flat.append({\n",
    "#                     \"n\": n,\n",
    "#                     \"type\": _type,\n",
    "#                     'ref': row['refNuc'],\n",
    "#                     'pos': row.get('pos', row.get('start')),\n",
    "#                     'alt': row['queryNuc'],\n",
    "#                     'gene': row.get('gene', '-'),\n",
    "#                     'ref_aa': aa_substitution['queryAA'],\n",
    "#                     'query_aa': aa_substitution['refAA']\n",
    "#                 })\n",
    "                \n",
    "# pd.DataFrame(nc_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(variant_table[variant_table['Total depth'] > MIN_DEPTH].to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_text = \"SARS-CoV-2 variants.\"\n",
    "\n",
    "n_extra_variants = (\n",
    "    sum(variant_table[\"Total depth\"] > MIN_DEPTH) if not variant_table.empty else 0\n",
    ")\n",
    "\n",
    "if n_extra_variants > 0:\n",
    "    legend_text += f\" An additional {n_extra_variants} variant{'s' if n_extra_variants > 1 else ''} <{MIN_DEPTH}× depth {'are' if n_extra_variants > 1 else 'is'} not shown.\"\n",
    "    \n",
    "    \n",
    "if os.environ.get(\"ONE_CODEX_REPORT_UUID\"):\n",
    "    legend_text += f\"\"\" \n",
    "         A variants TSV and consensus FASTA is available <a target=\"_blank\" href=\\\"{'https://app.onecodex.com/report/' + os.environ['ONE_CODEX_REPORT_UUID'] + '/files'}\\\">here</a>.\n",
    "        \"\"\"\n",
    "HTML(\n",
    "    '<div style=\"text-align: center; padding-top: 10px; font-size: 0.7em; color: #777;\"><em>'\n",
    "    + legend_text\n",
    "    + \"</em></div>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- Additional bioinformatics pipeline details are [available on GitHub](https://github.com/onecodex/sars-cov-2)\n",
    "- [Nextstrain](https://nextstrain.org/ncov) maintains an up-to-date analysis of SARS-CoV-2 (HCoV-19).\n",
    "- The [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) hosts viral genomes from ongoing outbreaks. Please [contact us](mailto:hello@onecodex.com) for help submitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add One Codex report ID to footer for reproducibility/data provenance (not yet in v0.7.2)\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "<style type='text/css'>\n",
    "@page {{\n",
    "    @bottom-center {{\n",
    "        content: \"{os.environ['ONE_CODEX_REPORT_UUID'] + ' -' if os.environ.get('ONE_CODEX_REPORT_UUID') else ''} NOT FOR DIAGNOSTIC USE\" !important;\n",
    "    }}\n",
    "}}\n",
    "</style>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a JSON too, including filtered variants <50x\n",
    "results = {\n",
    "    \"n_reads\": n_reads,\n",
    "    \"n_mapped_reads\": n_mapped_reads,\n",
    "    \"report_id\": os.environ.get(\"ONE_CODEX_REPORT_UUID\"), \n",
    "    \"sample_id\": os.environ.get(\"ONE_CODEX_SAMPLE_UUID\"),\n",
    "    \"variants\": variant_table.to_dict(orient='records'),\n",
    "    \"coverage\": cov,\n",
    "    \"coverage_over_50x\": cov_mindepth,\n",
    "    \"mean_depth\": mean_depth,\n",
    "    \"median_depth\": median_depth,\n",
    "    \"nextclade_results\": nextclade,\n",
    "    \"variant_table\": variant_table.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "with gzip.open(f\"{sample.filename}.report.json.gz\", \"w\") as f:\n",
    "    f.write(json.dumps(results).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up files\n",
    "!rm -f {sample.filename} snps.depth variants.log covid19.bam.bai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
